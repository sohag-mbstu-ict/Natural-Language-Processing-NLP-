{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"nWKIyDaRrIyK"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["**https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a**"],"metadata":{"id":"aHaEgRo3rPUE"}},{"cell_type":"code","source":["!pip install Unidecode"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VauO4s8MrlV8","executionInfo":{"status":"ok","timestamp":1662712876662,"user_tz":-360,"elapsed":12889,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"19062c1e-22e3-41af-b58a-81a48b5e7911"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting Unidecode\n","  Downloading Unidecode-1.3.4-py3-none-any.whl (235 kB)\n","\u001b[K     |████████████████████████████████| 235 kB 6.9 MB/s \n","\u001b[?25hInstalling collected packages: Unidecode\n","Successfully installed Unidecode-1.3.4\n"]}]},{"cell_type":"code","source":["!pip install autocorrect"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4Wor2DOrmdH","executionInfo":{"status":"ok","timestamp":1662712882352,"user_tz":-360,"elapsed":5696,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"161f8329-994c-41b4-f2b9-3c5ce70e393c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting autocorrect\n","  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n","\u001b[K     |████████████████████████████████| 622 kB 7.1 MB/s \n","\u001b[?25hBuilding wheels for collected packages: autocorrect\n","  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622382 sha256=885dd1126abfd63a651b966b1afec9c5543efb0faaff1aab2b570b1bd4a7e0bd\n","  Stored in directory: /root/.cache/pip/wheels/54/d4/37/8244101ad50b0f7d9bffd93ce58ed7991ee1753b290923934b\n","Successfully built autocorrect\n","Installing collected packages: autocorrect\n","Successfully installed autocorrect-2.6.1\n"]}]},{"cell_type":"code","source":["#https://towardsdatascience.com/cleaning-preprocessing-text-data-by-building-nlp-pipeline-853148add68a\n","# Importing Libraries \n","# Importing Libraries\n","import unidecode\n","import pandas as pd\n","import re\n","import time\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","from autocorrect import Speller\n","from bs4 import BeautifulSoup\n","from nltk.corpus import stopwords\n","from nltk import word_tokenize\n","import string\n","import timeit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mg35SAborOeV","executionInfo":{"status":"ok","timestamp":1662712884251,"user_tz":-360,"elapsed":1912,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"7ab5729b-f7bb-44b9-881b-086bc608c026"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/Cleaning\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o5VJMaWCr5IQ","executionInfo":{"status":"ok","timestamp":1662712910082,"user_tz":-360,"elapsed":25846,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"4cd58de9-3b9a-453f-a98c-b5ffcdc93047"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /Cleaning\n"]}]},{"cell_type":"code","source":["# Read Dataset\n","Df = pd.read_csv('/Cleaning/MyDrive/NLP/Abdullah/Restuarants Reviews Final.csv', encoding = 'latin-1')\n","print('Number of Data points : ', Df.shape[0])\n","print('Number of features :', Df.shape[1])\n","print('features :', Df.columns.values)\n","# Show Dataset\n","Df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258},"id":"bkld-5v_rmfg","executionInfo":{"status":"ok","timestamp":1662712910550,"user_tz":-360,"elapsed":508,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"eb4f9c27-bd71-4b56-e011-3c502e7687cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Data points :  1000\n","Number of features : 1\n","features : ['Review']\n"]},{"output_type":"execute_result","data":{"text/plain":["                                              Review\n","0  I had an amazing experience here in my short s...\n","1  I was 100 satisfied with the stay at intercont...\n","2  All of the facilities are modern & updated her...\n","3  I have been impressed by the excellent hospita...\n","4  Featuring 226 luxury rooms and suites, a selec..."],"text/html":["\n","  <div id=\"df-0130e670-7c4b-4890-91e0-4474b08c95aa\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I had an amazing experience here in my short s...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>I was 100 satisfied with the stay at intercont...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>All of the facilities are modern &amp; updated her...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>I have been impressed by the excellent hospita...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Featuring 226 luxury rooms and suites, a selec...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0130e670-7c4b-4890-91e0-4474b08c95aa')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0130e670-7c4b-4890-91e0-4474b08c95aa button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0130e670-7c4b-4890-91e0-4474b08c95aa');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# This command tells information about the attributes of Dataset.\n","Df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SqpTNBZ_rOgs","executionInfo":{"status":"ok","timestamp":1662712911421,"user_tz":-360,"elapsed":889,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"a83b871e-a4b3-4240-982a-bb4860ba9360"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 1 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   Review  1000 non-null   object\n","dtypes: object(1)\n","memory usage: 7.9+ KB\n"]}]},{"cell_type":"code","source":["# Shows statistics for every numerical column in our dataset.\n","Df.describe()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"id":"e0ZDkB7FrOkZ","executionInfo":{"status":"ok","timestamp":1662712911427,"user_tz":-360,"elapsed":149,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"3e729eb0-8e31-4399-f59b-4e5f61d58160"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       Review\n","count    1000\n","unique    995\n","top      Good\n","freq        3"],"text/html":["\n","  <div id=\"df-7d183e45-e579-44f7-b755-ae2693d1854e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>1000</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>995</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>Good</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d183e45-e579-44f7-b755-ae2693d1854e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7d183e45-e579-44f7-b755-ae2693d1854e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7d183e45-e579-44f7-b755-ae2693d1854e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["**Step-1 : Remove newlines & Tabs:**\n","\n","You may encounter lots of new lines for no reason in your textual dataset and tabs as well. So when you scrape data, those newlines and tabs that are required on the website for structured content are not required in your dataset and also get converted into useless characters like \\n, \\t. So, I have written a function that will delete all such nonsense."],"metadata":{"id":"PxVMbytBs-ji"}},{"cell_type":"code","source":["\n","def remove_newlines_tabs(text):\n","    \"\"\"\n","    This function will remove all the occurrences of newlines, tabs, and combinations like: \\\\n, \\\\.\n","    \n","    arguments:\n","        input_text: \"text\" of type \"String\". \n","                    \n","    return:\n","        value: \"text\" after removal of newlines, tabs, \\\\n, \\\\ characters.\n","        \n","    Example:\n","    Input : This is her \\\\ first day at this place.\\n Please,\\t Be nice to her.\\\\n\n","    Output : This is her first day at this place. Please, Be nice to her. \n","    \n","    \"\"\"\n","    \n","    # Replacing all the occurrences of \\n,\\\\n,\\t,\\\\ with a space.\n","    Formatted_text = text.replace('\\\\n', ' ').replace('\\n', ' ').replace('\\t',' ').replace('\\\\', ' ').replace('. com', '.com')\n","    return Formatted_text\n","# len of data :- 1618647 lac words"],"metadata":{"id":"7pjT2S8krOl7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","text=\"This is her \\\\ first day at this place.\\n Please,\\t Be nice to her.\\\\n\"\n","remove_newlines_tabs(text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"AIh_MDbtrOnT","executionInfo":{"status":"ok","timestamp":1662712911432,"user_tz":-360,"elapsed":143,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"e3e9fb58-de15-4d7e-d94e-d9a4e98a385e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'This is her   first day at this place.  Please,  Be nice to her. '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":[],"metadata":{"id":"zGF34CYErOpf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step-2 : Strip HTML Tags**\n","\n","When you scrape data, you may end up seeing HTML tags in the text of your dataset if you haven’t deal with it already while scraping. So, there is a need to deal with those tags later on. In this function, I am removing everything that matches HTML tags in my text."],"metadata":{"id":"UyAbuAX5trKY"}},{"cell_type":"code","source":["\n","def strip_html_tags(text):\n","    \"\"\" \n","    This function will remove all the occurrences of html tags from the text.\n","    \n","    arguments:\n","        input_text: \"text\" of type \"String\". \n","                    \n","    return:\n","        value: \"text\" after removal of html tags.\n","        \n","    Example:\n","    Input : This is a nice place to live. <IMG>\n","    Output : This is a nice place to live.  \n","    \"\"\"\n","    # Initiating BeautifulSoup object soup.\n","    soup = BeautifulSoup(text, \"html.parser\")\n","    # Get all the text other than html tags.\n","    stripped_text = soup.get_text(separator=\" \")\n","    return stripped_text\n","# len of string:- 1616053 lac words"],"metadata":{"id":"Dr5CXecLtqUK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","input=\"This is a nice place to live. <IMG>\"\n","strip_html_tags(input)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"e72esAzatqWw","executionInfo":{"status":"ok","timestamp":1662712911450,"user_tz":-360,"elapsed":148,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"04084cb2-d52c-40ff-b434-b46c3722358b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'This is a nice place to live. '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":[],"metadata":{"id":"4UbJdb3ZtqZS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step-3: Remove Links**\n","\n","This step will remove everything which is similar to hyperlinks of any type. I have added this function here as I have dealt with it on my dataset."],"metadata":{"id":"gLDAs2dpu0hf"}},{"cell_type":"code","source":["def remove_links(text):\n","    \"\"\"\n","    This function will remove all the occurrences of links.\n","    \n","    arguments:\n","        input_text: \"text\" of type \"String\". \n","                    \n","    return:\n","        value: \"text\" after removal of all types of links.\n","        \n","    Example:\n","    Input : To know more about this website: kajalyadav.com  visit: https://kajalyadav.com//Blogs\n","    Output : To know more about this website: visit:     \n","    \n","    \"\"\"\n","    \n","    # Removing all the occurrences of links that starts with https\n","    remove_https = re.sub(r'http\\S+', '', text)\n","    # Remove all the occurrences of text that ends with .com\n","    remove_com = re.sub(r\"\\ [A-Za-z]*\\.com\", \" \", remove_https)\n","    return remove_com\n","    "],"metadata":{"id":"4T3MRotStqbg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","input=\"To know more about this website: kajalyadav.com  visit: https://kajalyadav.com//Blogs\"\n","remove_links(input)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"KUtICSyotqdt","executionInfo":{"status":"ok","timestamp":1662712911458,"user_tz":-360,"elapsed":145,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"13abf1f6-6c97-4480-96ac-2fe6df63a7df"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'To know more about this website:   visit: '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":[],"metadata":{"id":"KMjLEVeHtqf5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Q6GVn_ZvtqiP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step-4: Remove Whitespaces**\n","\n","A single line function can be performed to remove extra whitespaces as mentioned below. This step is crucial before performing further NLP tasks."],"metadata":{"id":"cSNJ4MFcvlG0"}},{"cell_type":"code","source":["def remove_whitespace(text):\n","    \"\"\" This function will remove \n","        extra whitespaces from the text\n","    arguments:\n","        input_text: \"text\" of type \"String\". \n","                    \n","    return:\n","        value: \"text\" after extra whitespaces removed .\n","        \n","    Example:\n","    Input : How   are   you   doing   ?\n","    Output : How are you doing ?     \n","        \n","    \"\"\"\n","    pattern = re.compile(r'\\s+') \n","    Without_whitespace = re.sub(pattern, ' ', text)\n","    # There are some instances where there is no space after '?' & ')', \n","    # So I am replacing these with one space so that It will not consider two words as one token.\n","    text = Without_whitespace.replace('?', ' ? ').replace(')', ') ')\n","    return text \n","    "],"metadata":{"id":"4kyQx8zJvkV_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","input=\"How   are   you   doing   ?\"\n","remove_whitespace(input)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"vbPuzrURvkYf","executionInfo":{"status":"ok","timestamp":1662712911465,"user_tz":-360,"elapsed":134,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"622a85ac-f2bd-4585-8c3f-e810d0c65769"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'How are you doing  ? '"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":[],"metadata":{"id":"px5WKQfMvkbB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RFN1a-uqvkdN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4MOyJGFUvkfc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8CAPb4OSwwdB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**What are the main NLP text preprocessing steps?**\n","\n","The below list of text preprocessing steps is really important and I have written all these steps in a sequence how they should be."],"metadata":{"id":"QvrsDkabwxgw"}},{"cell_type":"code","source":[],"metadata":{"id":"cXd2JoWRwwf4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step-1: Remove Accented Characters**\n","\n","This is a crucial step to convert all characters like accented characters into machine-understandable language. So that further steps can be implemented easily. Accented characters are characters like â, î, or ô which have diacritics above the characters."],"metadata":{"id":"npxDchC6w1pV"}},{"cell_type":"code","source":["\n","# Code for accented characters removal\n","def accented_characters_removal(text):\n","    # this is a docstring\n","    \"\"\"\n","    The function will remove accented characters from the \n","    text contained within the Dataset.\n","       \n","    arguments:\n","        input_text: \"text\" of type \"String\". \n","                    \n","    return:\n","        value: \"text\" with removed accented characters.\n","        \n","    Example:\n","    Input : Málaga, àéêöhello\n","    Output : Malaga, aeeohello    \n","        \n","    \"\"\"\n","    # Remove accented characters from text using unidecode.\n","    # Unidecode() - It takes unicode data & tries to represent it to ASCII characters. \n","    text = unidecode.unidecode(text)\n","    return text\n","    "],"metadata":{"id":"490d4KxWwwip"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","input=\"Málaga, àéêöhello\"\n","accented_characters_removal(input)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"kdvQL4ecwwlI","executionInfo":{"status":"ok","timestamp":1662712911478,"user_tz":-360,"elapsed":131,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"10848429-a39e-4f15-b18a-f373b9524b8a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Malaga, aeeohello'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":[],"metadata":{"id":"u1yyULPgwwnL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step-2: Case Conversion**\n","\n","This is the next step in the series which is really important as case, CASE is two different words for the machine. So, you should be converting the case of the text in either lowercase or uppercase to proceed further."],"metadata":{"id":"pgTZ2SWExPN-"}},{"cell_type":"code","source":["\n","# Code for text lowercasing\n","def lower_casing_text(text):\n","    \n","    \"\"\"\n","    The function will convert text into lower case.\n","    \n","    arguments:\n","         input_text: \"text\" of type \"String\".\n","         \n","    return:\n","         value: text in lowercase\n","         \n","    Example:\n","    Input : The World is Full of Surprises!\n","    Output : the world is full of surprises!\n","    \n","    \"\"\"\n","    # Convert text to lower case\n","    # lower() - It converts all upperase letter of given string to lowercase.\n","    text = text.lower()\n","    return text\n","    "],"metadata":{"id":"83LJpQCExOcm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","input=\"The World is Full of Surprises!\"\n","lower_casing_text(input)\n"],"metadata":{"id":"9TDAWkjXxOfx","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1662712911495,"user_tz":-360,"elapsed":139,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"36653756-b12b-487f-db30-74e59861a62c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'the world is full of surprises!'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":[],"metadata":{"id":"BULt3LmuxOii"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step-3: Reducing repeated characters and punctuations**\n","\n","This step is important as there might be scenarios where characters are repeating more than necessary which can’t be detected by a spell checker later on. Therefore, there is a need to deal with such a scenario beforehand before applying the spell checker function. There is another scenario that I encounter while working, there can be repeating punctuations as well. So there is a need to encounter them as well.\n","\n","When we are very exciting, we do overwrite things that overwhelm readers.\n","\n","Example:- Cheeeeeerrrrrrss !!!!!!"],"metadata":{"id":"u0kWcUCMBwOH"}},{"cell_type":"markdown","source":["**The explanation for using some symbols in the above regex expression**\n","\n","\\1 → is equivalent to re.search(…). group(1). It refers to the first capturing group. \\1 matches the exact same text that was matched by the first capturing group.\n","\n","{1,} → It means we are matching for repetition that occurs more than one time.\n","\n","DOTALL -> It matches the newline character as well unlike the dot operator which matches everything in the given text except the newline character.\n","\n","sub() → This function is used to replace occurrences of a particular sub-string with another sub-string. This function takes as input the following: The substring to replace. The sub-string to replace with.\n","\n","r’\\1\\1' → It limits all the repetition to two characters.\n","\n","r’\\1' → Limits all the repetition to only one character.\n","\n","{2,} → It means to match for repetition that occurs more than two times"],"metadata":{"id":"vfAMHgjlCVUu"}},{"cell_type":"code","source":["# Code for removing repeated characters and punctuations\n","\n","def reducing_incorrect_character_repeatation(text):\n","    \"\"\"\n","    This Function will reduce repeatition to two characters \n","    for alphabets and to one character for punctuations.\n","    \n","    arguments:\n","         input_text: \"text\" of type \"String\".\n","         \n","    return:\n","        value: Finally formatted text with alphabets repeating to \n","        two characters & punctuations limited to one repeatition \n","        \n","    Example:\n","    Input : Realllllllllyyyyy,        Greeeeaaaatttt   !!!!?....;;;;:)\n","    Output : Reallyy, Greeaatt !?.;:)\n","    \n","    \"\"\"\n","    # Pattern matching for all case alphabets\n","    Pattern_alpha = re.compile(r\"([A-Za-z])\\1{1,}\", re.DOTALL)\n","    \n","    # Limiting all the  repeatation to two characters.\n","    Formatted_text = Pattern_alpha.sub(r\"\\1\\1\", text) \n","    \n","    # Pattern matching for all the punctuations that can occur\n","    Pattern_Punct = re.compile(r'([.,/#!$%^&*?;:{}=_`~()+-])\\1{1,}')\n","    \n","    # Limiting punctuations in previously formatted string to only one.\n","    Combined_Formatted = Pattern_Punct.sub(r'\\1', Formatted_text)\n","    \n","    # The below statement is replacing repeatation of spaces that occur more than two times with that of one occurrence.\n","    Final_Formatted = re.sub(' {2,}',' ', Combined_Formatted)\n","    return Final_Formatted"],"metadata":{"id":"EJCr_B1bxOlG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**The explanation for using some symbols in the above regex expression**\n","\n","\\1 → is equivalent to re.search(…). group(1). It refers to the first capturing group. \\1 matches the exact same text that was matched by the first capturing group.\n","\n","{1,} → It means we are matching for repetition that occurs more than one time.\n","\n","DOTALL -> It matches the newline character as well unlike the dot operator which matches everything in the given text except the newline character.\n","\n","sub() → This function is used to replace occurrences of a particular sub-string with another sub-string. This function takes as input the following: The substring to replace. The sub-string to replace with.\n","\n","r’\\1\\1' → It limits all the repetition to two characters.\n","\n","r’\\1' → Limits all the repetition to only one character.\n","\n","{2,} → It means to match for repetition that occurs more than two times"],"metadata":{"id":"CHyWLU61CZw-"}},{"cell_type":"code","source":[],"metadata":{"id":"Q_lHEquUCbXo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","Input = \"Realllllllllyyyyy,        Greeeeaaaatttt   !!!!?....;;;;:)\"\n","reducing_incorrect_character_repeatation(Input)\n"],"metadata":{"id":"R4QPUWu2xOny","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1662712911499,"user_tz":-360,"elapsed":134,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"441f7cd8-631a-40ad-f2dc-019bdabe0453"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Reallyy, Greeaatt !?.;:)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":[],"metadata":{"id":"en3RTf8MxOqh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tUfs9-1cCukq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step-4: Expand Contractions**\n","\n","In order to remove Stop words in the next step, It is crucial that you deal with contractions first. Contractions are nothing but shorthand forms for words like, Do not, would not, It is. Contractions are anything similar to these examples don’t, wouldn’t, It’s."],"metadata":{"id":"yvu33_6YCvce"}},{"cell_type":"code","source":["\n","CONTRACTION_MAP = {\n","\"ain't\": \"is not\",\n","\"aren't\": \"are not\",\n","\"can't\": \"cannot\",\n","\"can't've\": \"cannot have\",\n","\"'cause\": \"because\",\n","\"could've\": \"could have\",\n","\"couldn't\": \"could not\",\n","\"couldn't've\": \"could not have\",\n","\"didn't\": \"did not\",\n","\"doesn't\": \"does not\",\n","\"don't\": \"do not\",\n","\"hadn't\": \"had not\",\n","\"hadn't've\": \"had not have\",\n","\"hasn't\": \"has not\",\n","\"haven't\": \"have not\",\n","\"he'd\": \"he would\",\n","\"he'd've\": \"he would have\",\n","\"he'll\": \"he will\",\n","\"he'll've\": \"he he will have\",\n","\"he's\": \"he is\",\n","\"how'd\": \"how did\",\n","\"how'd'y\": \"how do you\",\n","\"how'll\": \"how will\",\n","\"how's\": \"how is\",\n","\"i'd\": \"i would\",\n","\"i'd've\": \"i would have\",\n","\"i'll\": \"i will\",\n","\"i'll've\": \"i will have\",\n","\"i'm\": \"i am\",\n","\"i've\": \"i have\",\n","\"isn't\": \"is not\",\n","\"it'd\": \"it would\",\n","\"it'd've\": \"it would have\",\n","\"it'll\": \"it will\",\n","\"it'll've\": \"it will have\",\n","\"it's\": \"it is\",\n","\"let's\": \"let us\",\n","\"ma'am\": \"madam\",\n","\"mayn't\": \"may not\",\n","\"might've\": \"might have\",\n","\"mightn't\": \"might not\",\n","\"mightn't've\": \"might not have\",\n","\"must've\": \"must have\",\n","\"mustn't\": \"must not\",\n","\"mustn't've\": \"must not have\",\n","\"needn't\": \"need not\",\n","\"needn't've\": \"need not have\",\n","\"o'clock\": \"of the clock\",\n","\"oughtn't\": \"ought not\",\n","\"oughtn't've\": \"ought not have\",\n","\"shan't\": \"shall not\",\n","\"sha'n't\": \"shall not\",\n","\"shan't've\": \"shall not have\",\n","\"she'd\": \"she would\",\n","\"she'd've\": \"she would have\",\n","\"she'll\": \"she will\",\n","\"she'll've\": \"she will have\",\n","\"she's\": \"she is\",\n","\"should've\": \"should have\",\n","\"shouldn't\": \"should not\",\n","\"shouldn't've\": \"should not have\",\n","\"so've\": \"so have\",\n","\"so's\": \"so as\",\n","\"that'd\": \"that would\",\n","\"that'd've\": \"that would have\",\n","\"that's\": \"that is\",\n","\"there'd\": \"there would\",\n","\"there'd've\": \"there would have\",\n","\"there's\": \"there is\",\n","\"they'd\": \"they would\",\n","\"they'd've\": \"they would have\",\n","\"they'll\": \"they will\",\n","\"they'll've\": \"they will have\",\n","\"they're\": \"they are\",\n","\"they've\": \"they have\",\n","\"to've\": \"to have\",\n","\"wasn't\": \"was not\",\n","\"we'd\": \"we would\",\n","\"we'd've\": \"we would have\",\n","\"we'll\": \"we will\",\n","\"we'll've\": \"we will have\",\n","\"we're\": \"we are\",\n","\"we've\": \"we have\",\n","\"weren't\": \"were not\",\n","\"what'll\": \"what will\",\n","\"what'll've\": \"what will have\",\n","\"what're\": \"what are\",\n","\"what's\": \"what is\",\n","\"what've\": \"what have\",\n","\"when's\": \"when is\",\n","\"when've\": \"when have\",\n","\"where'd\": \"where did\",\n","\"where's\": \"where is\",\n","\"where've\": \"where have\",\n","\"who'll\": \"who will\",\n","\"who'll've\": \"who will have\",\n","\"who's\": \"who is\",\n","\"who've\": \"who have\",\n","\"why's\": \"why is\",\n","\"why've\": \"why have\",\n","\"will've\": \"will have\",\n","\"won't\": \"will not\",\n","\"won't've\": \"will not have\",\n","\"would've\": \"would have\",\n","\"wouldn't\": \"would not\",\n","\"wouldn't've\": \"would not have\",\n","\"y'all\": \"you all\",\n","\"y'all'd\": \"you all would\",\n","\"y'all'd've\": \"you all would have\",\n","\"y'all're\": \"you all are\",\n","\"y'all've\": \"you all have\",\n","\"you'd\": \"you would\",\n","\"you'd've\": \"you would have\",\n","\"you'll\": \"you will\",\n","\"you'll've\": \"you will have\",\n","\"you're\": \"you are\",\n","\"you've\": \"you have\",\n","}\n"],"metadata":{"id":"Y6Q_HLsfCunS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The code for expanding contraction words\n","def expand_contractions(text, contraction_mapping =  CONTRACTION_MAP):\n","    \"\"\"expand shortened words to the actual form.\n","       e.g. don't to do not\n","    \n","       arguments:\n","            input_text: \"text\" of type \"String\".\n","         \n","       return:\n","            value: Text with expanded form of shorthened words.\n","        \n","       Example: \n","       Input : ain't, aren't, can't, cause, can't've\n","       Output :  is not, are not, cannot, because, cannot have \n","    \n","     \"\"\"\n","    # Tokenizing text into tokens.\n","    list_Of_tokens = text.split(' ')\n","    print(\"text : \",text)\n","\n","    # Checking for whether the given token matches with the Key & replacing word with key's value.\n","    \n","    # Check whether Word is in lidt_Of_tokens or not.\n","    for Word in list_Of_tokens: \n","        # Check whether found word is in dictionary \"Contraction Map\" or not as a key. \n","         if Word in CONTRACTION_MAP: \n","                # If Word is present in both dictionary & list_Of_tokens, replace that word with the key value.\n","                list_Of_tokens = [item.replace(Word, CONTRACTION_MAP[Word]) for item in list_Of_tokens]\n","                \n","    # Converting list of tokens to String.\n","    String_Of_tokens = ' '.join(str(e) for e in list_Of_tokens) \n","    return String_Of_tokens     "],"metadata":{"id":"Gr1ITkkpCup6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","Input = \"ain't aren't can't cause can't've\"\n","print(expand_contractions(Input,CONTRACTION_MAP ))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ls9wSoTNCusL","executionInfo":{"status":"ok","timestamp":1662713515370,"user_tz":-360,"elapsed":529,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"0750df35-550d-4696-d1ed-23afb5d2cbc6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["text :  ain't aren't can't cause can't've\n","is not are not cannot cause cannot've\n"]}]},{"cell_type":"code","source":["print(Input.split(' '))"],"metadata":{"id":"aDMAkSAOCuun","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1662713522691,"user_tz":-360,"elapsed":474,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"a1c2ab8a-1088-4490-faa0-8c9946ccbb04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"ain't\", \"aren't\", \"can't\", 'cause', \"can't've\"]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"K9t6Eep1cvGB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step-5: Remove Special Characters**\n","\n","In this step, We will go to learn how to remove special characters, why to remove them, and what special characters you should be keeping.\n","\n","So, I have written a function that will remove a set of specified special characters and will gonna keep some important punctuations like (,.?!) excluding brackets. Special characters should be removed as when we gonna tokenized the text, later on, the punctuations don’t occur with more weightage."],"metadata":{"id":"PjXAmZdudKRO"}},{"cell_type":"markdown","source":["**To Remove numbers from the text :**\n","\n","All you need is to modify the given regex to\n","\n","**Formatted_Text = re.sub(r\"[^a-zA-Z:$-,%.?!]+\", ' ', text)**\n","\n","Just exclude the 0–9 range so as to remove all representation of numbers from the text. I didn’t perform this particular step on my dataset as the numbers are really important in my case to consider.\n","\n","Punctuations that I am considering are Important as per my Dataset as I have to perform text summarization later on.\n","\n",",.?! → These are some frequent punctuations that occur a lot and needed to be preserved to understand the context of the text.\n","\n",": → This one is also frequent as per the Dataset. It is important to keep because it is giving sense whenever there is an occurrence of time like 9:05 p.m.\n","\n","% → This one is also frequently used in many articles and telling more precisely about the data, facts & figures.\n","\n","$ → This one is used in many articles where prices are considered. So, omitting this symbol will not give much sense about those prices that are left as just some numbers only."],"metadata":{"id":"TzFKBMAzliqt"}},{"cell_type":"code","source":["\n","# The code for removing special characters\n","def removing_special_characters(text):\n","    \"\"\"Removing all the special characters except the one that is passed within \n","       the regex to match, as they have imp meaning in the text provided.\n","   \n","    \n","    arguments:\n","         input_text: \"text\" of type \"String\".\n","         \n","    return:\n","        value: Text with removed special characters that don't require.\n","        \n","    Example: \n","    Input  : Hello, K-a-j-a-l. Thi*s is $100.05 : the payment that you will recieve! (Is this okay?) \n","    Output :  Hello, Kajal. This is $100.05 : the payment that you will recieve! Is this okay?\n","    \n","   \"\"\"\n","    # The formatted text after removing not necessary punctuations.\n","    Formatted_Text = re.sub(r\"[^a-zA-Z0-9$-,%.?!]+\", ' ', text)\n","    #print(\"Formatted_Text : \",Formatted_Text)\n","    # In the above regex expression,I am providing necessary set of punctuations that are frequent in this particular dataset.\n","    return Formatted_Text\n"],"metadata":{"id":"5DZn9kFucvIQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","Input = \"Hello, K-a-j-a-l. Thi*s is $100.05 : the payment that you will recieve! (Is this okay?)\"\n","removing_special_characters(Input)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"RrOLkRp5cvOV","executionInfo":{"status":"ok","timestamp":1662715770379,"user_tz":-360,"elapsed":773,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"64efa318-f414-47d6-94c4-a60c3d766ef1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Hello, K a j a l. Thi*s is $100.05 the payment that you will recieve! (Is this okay?)'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":[],"metadata":{"id":"qwDTRDXEcvQh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_vdPQHK4cvWB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Step-7: Correcting Mis-spelled words**\n","\n","You should be very careful while attempting this one step. As this function may change the true meaning of the word. So you have to be very careful and try to see how things unfold on applying this function. If you are working on some industry-specific dataset, then you may need to consider relating the dictionary which tells this function explicitly to keep those specific words as it is."],"metadata":{"id":"Ij-JvoYGl-At"}},{"cell_type":"code","source":["\n","# The code for spelling corrections\n","def spelling_correction(text):\n","    ''' \n","    This function will correct spellings.\n","    \n","    arguments:\n","         input_text: \"text\" of type \"String\".\n","         \n","    return:\n","        value: Text after corrected spellings.\n","        \n","    Example: \n","    Input : This is Oberois f3rom Dlhi whoop came heree to studdy.\n","    Output : This is Oberoi from Delhi who came here to study.\n","      \n","    \n","    '''\n","    # Check for spellings in English language\n","    spell = Speller(lang='en')\n","    Corrected_text = spell(text)\n","    return Corrected_text\n"],"metadata":{"id":"BssEaYh2cvYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","Input = \"This is Oberois from Dlhi who came heree to studdy.\"\n","spelling_correction(Input)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"blHaaQgTcvas","executionInfo":{"status":"ok","timestamp":1662716024766,"user_tz":-360,"elapsed":11,"user":{"displayName":"Sohag Hossain","userId":"13148063414152174256"}},"outputId":"3973e379-3208-42a5-cb06-678f07c1cb67"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'This is Oberoi from Delhi who came here to study.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":72}]},{"cell_type":"code","source":[],"metadata":{"id":"u48T6UJFmMdZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jVQ3s9KJcvlb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zMLT9ma_vkhm"},"execution_count":null,"outputs":[]}]}