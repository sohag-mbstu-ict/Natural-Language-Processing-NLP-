{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8XYoeVH6K0h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://kavita-ganesan.com/gensim-word2vec-tutorial-starter-code/#.Y2cy3nZBzIX"
      ],
      "metadata": {
        "id": "_HXkA56qdhmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/kavgan/nlp-in-practice/blob/master/word2vec/Word2Vec.ipynb"
      ],
      "metadata": {
        "id": "iXobwZa_deR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/kavgan/nlp-in-practice/blob/master/word2vec/Word2Vec.ipynb"
      ],
      "metadata": {
        "id": "SXDd8kOade5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/kavgan/nlp-in-practice/blob/master/word2vec/Word2Vec.ipynb"
      ],
      "metadata": {
        "id": "_Jc0x-JLdfs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports needed and logging\n",
        "import gzip\n",
        "import gensim \n",
        "import logging\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
      ],
      "metadata": {
        "id": "qO47WSQUK1kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/Similar_Word\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYh9BhwdK1m4",
        "outputId": "7ee0db0f-401b-44bc-fd34-55119b061983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /Similar_Word\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#!unzip /Similar_Word/MyDrive/NLP/Distance_Between_two_words/OpinRankDatasetWithJudgments.zip -d /Similar_Word/MyDrive/NLP/Distance_Between_two_words\n",
        "            "
      ],
      "metadata": {
        "id": "igdy-pZ_K1pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_file = \"/Similar_Word/MyDrive/NLP/Distance_Between_two_words/reviews_data.txt.gz\"\n",
        "with gzip.open (input_file, 'rb') as f:\n",
        "        for i,line in enumerate (f):\n",
        "            print(line)\n",
        "            break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaugM4cAK1r2",
        "outputId": "ebe42bfc-27e2-47af-9541-c8f9e433b3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_input(input_file):\n",
        "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
        "    \n",
        "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
        "    \n",
        "    with gzip.open (input_file, 'rb') as f:\n",
        "        for i, line in enumerate (f): \n",
        "\n",
        "            if (i%10000==0):\n",
        "                logging.info (\"read {0} reviews\".format (i))\n",
        "            # do some pre-processing and return a list of words for each review text\n",
        "            yield gensim.utils.simple_preprocess (line)\n",
        "\n",
        "# read the tokenized reviews into a list\n",
        "# each review item becomes a serries of words\n",
        "# so this becomes a list of lists\n",
        "documents = list (read_input (input_file))\n",
        "logging.info (\"Done reading data file\")\n"
      ],
      "metadata": {
        "id": "_nLuT19OK1uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)\n",
        "model.train(documents,total_examples=len(documents),epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1S4NvsyNK1we",
        "outputId": "eec9eeac-333b-4aa8-c5c8-66ce20c07cad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(303504528, 415193580)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "w1 = \"dirty\"\n",
        "model.wv.most_similar (positive=w1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otKnTrqhK1yU",
        "outputId": "64285cc2-f32f-4c2c-afea-e892d0c642a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('filthy', 0.8618006110191345),\n",
              " ('stained', 0.7831227779388428),\n",
              " ('unclean', 0.773486852645874),\n",
              " ('dusty', 0.7694820761680603),\n",
              " ('smelly', 0.7617112398147583),\n",
              " ('grubby', 0.7551862597465515),\n",
              " ('grimy', 0.7347296476364136),\n",
              " ('dingy', 0.7327849864959717),\n",
              " ('soiled', 0.7295088171958923),\n",
              " ('mouldy', 0.7270488739013672)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# look up top 6 words similar to 'polite'\n",
        "w1 = [\"polite\"]\n",
        "model.wv.most_similar (positive=w1,topn=6)\n"
      ],
      "metadata": {
        "id": "o87cVa3XK10o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d55cd8-2167-4be3-a8d8-272c24eb5d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('courteous', 0.9261513948440552),\n",
              " ('friendly', 0.8334428668022156),\n",
              " ('cordial', 0.811875581741333),\n",
              " ('professional', 0.7865085005760193),\n",
              " ('attentive', 0.770498514175415),\n",
              " ('curteous', 0.7600521445274353)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# look up top 6 words similar to 'shocked'\n",
        "w1 = [\"shocked\"]\n",
        "model.wv.most_similar (positive=w1,topn=6)\n"
      ],
      "metadata": {
        "id": "TLst4okjK122",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b84c1ec-bdf5-4045-a21d-0dc3dc0c2052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('horrified', 0.8125640749931335),\n",
              " ('amazed', 0.7998853921890259),\n",
              " ('appalled', 0.7774959802627563),\n",
              " ('astonished', 0.7673192024230957),\n",
              " ('stunned', 0.7485215067863464),\n",
              " ('dismayed', 0.737923264503479)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get everything related to stuff on the bed\n",
        "w1 = [\"bed\",'sheet','pillow']\n",
        "w2 = ['couch']\n",
        "model.wv.most_similar (positive=w1,negative=w2,topn=10)\n"
      ],
      "metadata": {
        "id": "YZUY9sVBK15L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4109e2f-1300-4e6b-9e9c-3505e1793bda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('duvet', 0.7087066173553467),\n",
              " ('blanket', 0.6890629529953003),\n",
              " ('mattress', 0.6853978633880615),\n",
              " ('matress', 0.667702317237854),\n",
              " ('quilt', 0.6663302779197693),\n",
              " ('pillowcase', 0.6542825698852539),\n",
              " ('sheets', 0.6388118267059326),\n",
              " ('foam', 0.635508120059967),\n",
              " ('pillows', 0.6337054371833801),\n",
              " ('pillowcases', 0.6203763484954834)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Similarity between two words in the vocabulary**\n",
        "\n",
        "You can even use the Word2Vec model to return the similarity between two words that are present in the vocabulary."
      ],
      "metadata": {
        "id": "z_v_Wdo7SQW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# similarity between two different words\n",
        "model.wv.similarity(w1=\"dirty\",w2=\"smelly\")\n"
      ],
      "metadata": {
        "id": "89blcmi_K17u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ce0126-f35a-4568-8749-5e635facd717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7617112"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# similarity between two identical words\n",
        "model.wv.similarity(w1=\"dirty\",w2=\"dirty\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NV4X0lwNSSju",
        "outputId": "151bfbbe-d951-4e34-f721-23c4f4684e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# similarity between two unrelated words\n",
        "model.wv.similarity(w1=\"dirty\",w2=\"clean\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__DpveVISSmc",
        "outputId": "81814e91-4e59-4069-d65f-f47891ec37e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.27082956"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q3N7eh_UTzsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "royT1Ji0Tzu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ox16gYgTzxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Under the hood, the above three snippets computes the cosine similarity between the two specified words using word vectors of each. From the scores, it makes sense that dirty is highly similar to smelly but dirty is dissimilar to clean. If you do a similarity between two identical words, the score will be 1.0 as the range of the cosine similarity score will always be between [0.0-1.0]. You can read more about cosine similarity scoring here."
      ],
      "metadata": {
        "id": "cU6vBOkuSfvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Find the odd one out**\n",
        "\n",
        "You can even use Word2Vec to find odd items given a list of items."
      ],
      "metadata": {
        "id": "g-hWHfBOSi8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Which one is the odd one out in this list?\n",
        "model.wv.doesnt_match([\"bed\",\"pillow\",\"duvet\",\"shower\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "K2tCIwBsSSpB",
        "outputId": "14d34670-2e0b-4fe3-c46e-f7f66ea49331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'shower'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understanding some of the parameters**\n",
        "\n",
        "To train the model earlier, we had to set some parameters. Now, let's try to understand what some of them mean. For reference, this is the command that we used to train the model.\n",
        "\n",
        "\n",
        "model = gensim.models.Word2Vec (documents, size=150, window=10, min_count=2, workers=10)"
      ],
      "metadata": {
        "id": "ZLyaue9gSrXL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gLkSsJOpSSro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**size**\n",
        "\n",
        "The size of the dense vector to represent each token or word. If you have very limited data, then size should be a much smaller value. If you have lots of data, its good to experiment with various sizes. A value of 100-150 has worked well for me.\n",
        "\n",
        "**window**\n",
        "\n",
        "The maximum distance between the target word and its neighboring word. If your neighbor's position is greater than the maximum window width to the left and the right, then, some neighbors are not considered as being related to the target word. In theory, a smaller window should give you terms that are more related. If you have lots of data, then the window size should not matter too much, as long as its a decent sized window.\n",
        "\n",
        "**min_count**\n",
        "\n",
        "Minimium frequency count of words. The model would ignore words that do not statisfy the min_count. Extremely infrequent words are usually unimportant, so its best to get rid of those. Unless your dataset is really tiny, this does not really affect the model.\n",
        "\n",
        "**workers**\n",
        "\n",
        "How many threads to use behind the scenes?"
      ],
      "metadata": {
        "id": "UTkpZNvbSymM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**When should you use Word2Vec?**\n",
        "\n",
        "There are many application scenarios for Word2Vec. Imagine if you need to build a sentiment lexicon. Training a Word2Vec model on large amounts of user reviews helps you achieve that. You have a lexicon for not just sentiment, but for most words in the vocabulary.\n",
        "\n",
        "\n",
        "Beyond, raw unstructured text data, you could also use Word2Vec for more structured data. For example, if you had tags for a million stackoverflow questions and answers, you could find tags that are related to a given tag and recommend the related ones for exploration. You can do this by treating each set of co-occuring tags as a \"sentence\" and train a Word2Vec model on this data. Granted, you still need a large number of examples to make it work."
      ],
      "metadata": {
        "id": "mqzQUEm7S7eM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZuTkt4mDSSt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FATQO78YSSwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0OV358paSSyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "th-hpLOfSS0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H_Rx07CUSS3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PadBQWUtSS5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zYFhI1LEK19x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y8lgIK4BK1_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tjcdmULeK2Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fmfsj8LDK2IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEKQpfqLjWyv"
      },
      "outputs": [],
      "source": [
        "# https://www.educative.io/answers/how-to-find-similarity-between-two-words-using-nlp\n",
        "# https://python.gotrained.com/nltk-edit-distance-jaccard-distance/\n",
        "# https://www.kdnuggets.com/2018/08/emotion-sentiment-analysis-practitioners-guide-nlp-5.html\n",
        "# https://www.kdnuggets.com/2022/10/10-cheat-sheets-need-ace-data-science-interview.html\n",
        "# https://monkeylearn.com/sentiment-analysis/\n",
        "# https://flavien-vidal.medium.com/similarity-distances-for-natural-language-processing-16f63cd5ba55\n",
        "# https://colab.research.google.com/github/shankygupta79/GoogleCollabFiles/blob/master/Word2Vec.ipynb#scrollTo=HDjdWIER5Whn\n",
        "# https://soumilshah1995.blogspot.com/2020/05/lets-build-simple-nlp-model-that.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.educative.io/answers/how-to-find-similarity-between-two-words-using-nlp"
      ],
      "metadata": {
        "id": "qa9Xh5M_jd_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.educative.io/answers/how-to-find-similarity-between-two-words-using-nlp"
      ],
      "metadata": {
        "id": "-Cx7B3FVjerj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.educative.io/answers/how-to-find-similarity-between-two-words-using-nlp"
      ],
      "metadata": {
        "id": "RnSbsPbkjfMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gensim\n",
        "from gensim.models import word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "nxMiD3NNjaHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "wv = api.load('word2vec-google-news-300')\n",
        "\n",
        "vec_king = wv['king']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a67BArejaKY",
        "outputId": "f388b16c-c036-49c2-b874-b9b6c2746846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install gensim\n",
        "!pip install scikit-learn\n"
      ],
      "metadata": {
        "id": "goqNlpDijaMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3d360e-e4b3-43cc-f484-8816e13ac1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install gensim\n",
        "!pip install scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvqSM8BbjaOl",
        "outputId": "6a9b5e64-0a0c-4cfd-d686-7be7f6d9d25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "print('Imported Successfully!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMCTarqDjaQ2",
        "outputId": "e50f1df9-3e9f-454e-843e-1fa32da428f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "v_apple = wv['banana']\n",
        "v_mango = wv['mango']\n",
        "cosine_similarity([v_apple],[v_mango])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuKU0W0mn8-G",
        "outputId": "2bd48bcd-1722-4cab-86e7-7f3e96fdd83c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.63652116]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "v_apple = wv['serve']\n",
        "v_mango = wv['service']\n",
        "cosine_similarity([v_apple],[v_mango])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dDGIhkrn9Ah",
        "outputId": "fb69666a-3778-40fd-ab3f-a7216c688a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.32593498]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "v_apple = wv['happy']\n",
        "v_mango = wv['unhappy']\n",
        "cosine_similarity([v_apple],[v_mango])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi0yugSXn9DV",
        "outputId": "27c97e87-e0ce-4aec-b892-6862eace14a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6128039]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "81CpCI8EoH4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pUx3PYItoH67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RtWB5_pzjaTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MThMtpSijaUx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}